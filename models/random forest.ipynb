{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f48b4807",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import networkx as nx\n",
    "import networkx.algorithms as alg\n",
    "\n",
    "import dgl\n",
    "from dgl.nn import RelGraphConv\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from dgl.nn import GraphConv, AvgPooling\n",
    "from dgl.nn.pytorch import Sequential\n",
    "\n",
    "from dgl.dataloading import GraphDataLoader\n",
    "from torch.utils.data import Dataset, DataLoader,TensorDataset,random_split,SubsetRandomSampler, ConcatDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "import pickle\n",
    "\n",
    "from copy import deepcopy\n",
    "from utils import *\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3821a97",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (Temp/ipykernel_27768/2825711784.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\ondra\\AppData\\Local\\Temp/ipykernel_27768/2825711784.py\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    nx_train_set, nx_val_set, nx_test_set = pickle.load(f)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "    pickle_name = 'nx_dataset.pickle'\n",
    "with open(pickle_name, 'rb') as f:\n",
    "    nx_train_set, nx_val_set, nx_test_set = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c825f7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# e2id = {'title':0, \n",
    "#         'link':1,\n",
    "#         'domain':2,\n",
    "#         'reversed_title':3,\n",
    "#         'reversed_link':4,\n",
    "#        }\n",
    "\n",
    "\n",
    "train_set = add_time_difference(nx_train_set)\n",
    "val_set = add_time_difference(nx_val_set)\n",
    "test_set = add_time_difference(nx_test_set)\n",
    "print('time done')\n",
    "\n",
    "train_set = add_domain(train_set)\n",
    "val_set = add_domain(val_set)\n",
    "test_set = add_domain(test_set)\n",
    "print('domain done')\n",
    "\n",
    "train_set = add_sna(train_set)\n",
    "val_set = add_sna(val_set)\n",
    "test_set = add_sna(test_set)\n",
    "print('sna done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391186a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671ddf30",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=2)\n",
    "def add_node_embedding(dataset):\n",
    "    fvs = []\n",
    "    labels = []\n",
    "    for j in range(len(dataset)):\n",
    "        no_time_flag = 0\n",
    "        g = dataset[j][0]\n",
    "        levels = np.zeros(3)\n",
    "        snas = np.zeros((len(g.nodes), 5))\n",
    "        time_diffs = []\n",
    "        for i in range(len(g.nodes)):\n",
    "            n = g.nodes[i]\n",
    "            g.nodes[i]['h'] = torch.tensor([\n",
    "                0.,0., 0.,  # one hot level encoding\n",
    "                n['time_diff'], n['no_time'],\n",
    "                *n['sna']\n",
    "            ])\n",
    "            snas[i] = n['sna']\n",
    "            levels[g.nodes[i]['level']] += 1\n",
    "            if n['no_time'] != 1:\n",
    "                time_diffs.append(n['time_diff'])\n",
    "            else: \n",
    "                no_time_flag += 1\n",
    "        links = 0\n",
    "        titles = 0\n",
    "        domain = 0\n",
    "        for e in g.edges:\n",
    "            if g.edges[e]['link_type']=='link':\n",
    "                links +=1\n",
    "                \n",
    "            if g.edges[e]['link_type']=='title':\n",
    "                titles +=1\n",
    "            if g.edges[e]['link_type']=='domain':\n",
    "                domain += 0.5\n",
    "                \n",
    "        levels /= len(g.nodes)\n",
    "        time_diff_mean = np.asarray(time_diffs).mean()\n",
    "        time_diff_std = np.asarray(time_diffs).std()\n",
    "        no_time_flag /= len(g.nodes)\n",
    "        \n",
    "        mean_sna = snas.mean(0)\n",
    "        \n",
    "        fv = np.array([*levels, time_diff_mean, time_diff_std, no_time_flag,  *mean_sna, len(g.nodes), len(g.edges), links/(links+titles), domain/len(g.nodes)])\n",
    "        fvs.append(fv)\n",
    "        labels.append(dataset[j][1])\n",
    "    return np.asarray(fvs), np.asarray(labels)\n",
    "\n",
    "train_fvs, train_labels = add_node_embedding(train_set)\n",
    "val_fvs, val_labels = add_node_embedding(val_set)\n",
    "test_fvs, test_labels = add_node_embedding(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b27ed9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from itertools import product\n",
    "\n",
    "n_estimators = [1, 5, 10, 20, 50, 100]\n",
    "max_depths = [1, 2, 5, 10, 20, 50, 100]\n",
    "criterions = ['gini', 'entropy']\n",
    "params = list(product(n_estimators, criterions, max_depths))\n",
    "# print(list(params)\n",
    "train_accs, val_accs = [], []\n",
    "splits=StratifiedKFold(n_splits=5,shuffle=True, random_state=42)\n",
    "\n",
    "results = []\n",
    "for n_estimator, criterion, max_depth in params:\n",
    "    model_results = []\n",
    "    for fold, (train_idx, val_idx) in enumerate(splits.split(np.arange(len(train_fvs)), train_labels)):\n",
    "        split_train_fvs = train_fvs[train_idx]\n",
    "        split_train_labels = train_labels[train_idx]\n",
    "        split_val_fvs = train_fvs[val_idx]\n",
    "        split_val_labels = train_labels[val_idx]\n",
    "        \n",
    "        clf = RandomForestClassifier(n_estimators=n_estimator, max_depth=max_depth, criterion=criterion, random_state=42)\n",
    "        clf.fit(split_train_fvs, split_train_labels)\n",
    "    \n",
    "#         train_accs.append((clf.predict(train_fvs) == train_labels).mean())\n",
    "        model_results.append((clf.predict(split_val_fvs)==split_val_labels).mean())\n",
    "        print('{:.2f}'.format(100*model_results[-1]), end=' ')\n",
    "    print('\\t', np.asarray(model_results).mean())\n",
    "    results.append(np.asarray(model_results).mean())\n",
    "    \n",
    "#     print(val_accs[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcab1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=2)\n",
    "val_accs = np.asarray(results)\n",
    "val_accs.argmax()\n",
    "print(f'CV Val acc {100*val_accs.max()}%')\n",
    "\n",
    "n_estimator, criterion, max_depth = list(params)[val_accs.argmax()]\n",
    "clf = RandomForestClassifier(n_estimators=n_estimator, criterion=criterion, max_depth=max_depth, random_state=42)\n",
    "clf.fit(train_fvs, train_labels)\n",
    "test_acc = 100*(clf.predict(test_fvs)==test_labels).mean()\n",
    "val_acc =  100*(clf.predict(val_fvs)==val_labels).mean()\n",
    "print(f'Val acc {val_acc}%')\n",
    "print(f'best parameters: n_estimators {n_estimator}, criterion {criterion}, max_depth {max_depth}, test accuracy is {test_acc}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5933152f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a661250",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c0fd83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe449db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc99ede",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48428106",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a2b1ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1bba0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
